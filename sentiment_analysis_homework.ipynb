{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация отзывов (домашнее задание)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier #модуль для построения линейных моделей\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исследуем наш датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(заодно потренеруемся в работе с pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46501, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим на объем датасета (сколько в нем строк и колонок): \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Эпиграф Добро которое ты делаешь от сердца ты ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Теперь это один из моих любимых фильмов в жанр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Что скрыто в фильме Лучше не бывает Одна шикар...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Перед нами очень милое и доброе кино которое л...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Завязка Мелвин Удал популярный писатель Нет не...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      1  Эпиграф Добро которое ты делаешь от сердца ты ...\n",
       "1      1  Теперь это один из моих любимых фильмов в жанр...\n",
       "2      1  Что скрыто в фильме Лучше не бывает Одна шикар...\n",
       "3      1  Перед нами очень милое и доброе кино которое л...\n",
       "4      1  Завязка Мелвин Удал популярный писатель Нет не..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим шапку:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    36480\n",
       " 0     5645\n",
       "-1     4376\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим, какие значения есть в Labels и как количественно распределяются\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизируем текст с помощью CountVectorizer c настройками по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сначала инициализируем CountVectorizer:\n",
    "vec = CountVectorizer()\n",
    "#Сделаем матрицу из нашего текста (мешок слов BagOfWords), то есть берем текст из колонки text:\n",
    "bow = vec.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 366655)\t1\n",
      "  (0, 70309)\t1\n",
      "  (0, 124109)\t2\n",
      "  (0, 329109)\t4\n",
      "  (0, 64758)\t2\n",
      "  (0, 197067)\t7\n",
      "  (0, 290666)\t1\n",
      "  (0, 41924)\t1\n",
      "  (0, 289185)\t2\n",
      "  (0, 323513)\t1\n",
      "  (0, 75776)\t1\n",
      "  (0, 163170)\t18\n",
      "  (0, 220963)\t1\n",
      "  (0, 259033)\t1\n",
      "  (0, 106598)\t1\n",
      "  (0, 78333)\t9\n",
      "  (0, 293257)\t1\n",
      "  (0, 357853)\t11\n",
      "  (0, 136044)\t1\n",
      "  (0, 367689)\t2\n",
      "  (0, 344796)\t2\n",
      "  (0, 367672)\t5\n",
      "  (0, 300485)\t2\n",
      "  (0, 195082)\t1\n",
      "  (0, 77977)\t2\n",
      "  :\t:\n",
      "  (46500, 43241)\t1\n",
      "  (46500, 263498)\t1\n",
      "  (46500, 91943)\t1\n",
      "  (46500, 93785)\t1\n",
      "  (46500, 311339)\t1\n",
      "  (46500, 16669)\t1\n",
      "  (46500, 161418)\t1\n",
      "  (46500, 297299)\t1\n",
      "  (46500, 230425)\t1\n",
      "  (46500, 346196)\t1\n",
      "  (46500, 310277)\t1\n",
      "  (46500, 350057)\t1\n",
      "  (46500, 82140)\t1\n",
      "  (46500, 222345)\t1\n",
      "  (46500, 268600)\t1\n",
      "  (46500, 318074)\t1\n",
      "  (46500, 258568)\t1\n",
      "  (46500, 230334)\t1\n",
      "  (46500, 244816)\t1\n",
      "  (46500, 304990)\t1\n",
      "  (46500, 227452)\t1\n",
      "  (46500, 361464)\t1\n",
      "  (46500, 55383)\t1\n",
      "  (46500, 218775)\t1\n",
      "  (46500, 9487)\t1\n"
     ]
    }
   ],
   "source": [
    "#Посмотрим, как выглядит признаковое представление нашего текста:\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<46501x369844 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11693675 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46501"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверим длину текстов:\n",
    "len(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество признаков-частот слов в CountVectorizer:369844\n"
     ]
    }
   ],
   "source": [
    "#Посмотрим на количество признаков в матрице (просто вызов bow дает нам ту же информацию): \n",
    "print('Количество признаков-частот слов в CountVectorizer:' + str(bow.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сделаем тестовые и обучающие выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем обучать модель на обучающей выборке и проверять ее качество на тесте.\n",
    "Чтобы собрать тестовую и обучающую выборки из исходных данных, используем функцию кросс-валидации train_test_split, реализованной в scikit-learn. Она позволяет нам построить разовое разбиение данных на обучение и тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#В качестве аргумента функция принимает набор данных, которые мы хотим разбить (bow), \n",
    "#набор меток классов (df.label), и также ей можно указать соотношение, в котором мы хотим разбивать данные\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(bow, df.label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<34875x369844 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 8764370 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Смотрим на размер обучающей выборки\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11626x369844 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2929305 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Смотрим на размер тестовой выборки: \n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логистическая регрессия (с настройками по умолчанию)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Создание объекта-классификатора (модель). Строим логистическую регрессию и используем  для этого класс LogisticRegression:\n",
    "lr = LogisticRegression(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Обучение нашего классификатора (модели). Передаем данные, на которых нужно обучаться (наш векторизированный текст) и метки классов: \n",
    "lr.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Применение обученного классификатора. Cтроим предсказания с помощью метода predict:\n",
    "predicted_labels = lr.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31355    1\n",
      "3028     1\n",
      "24927    1\n",
      "43461    1\n",
      "23369    1\n",
      "3952     1\n",
      "4103     1\n",
      "31972    0\n",
      "10975    1\n",
      "25047    1\n",
      "22469    1\n",
      "41507    1\n",
      "46453    1\n",
      "28542   -1\n",
      "43194    1\n",
      "2971     1\n",
      "25347    0\n",
      "32681   -1\n",
      "30127    0\n",
      "32074   -1\n",
      "33435    0\n",
      "4393     1\n",
      "9602     1\n",
      "17806   -1\n",
      "10098    1\n",
      "42048    1\n",
      "33922    0\n",
      "16498    1\n",
      "10402    1\n",
      "36737    1\n",
      "        ..\n",
      "8899     1\n",
      "21041    1\n",
      "15245    1\n",
      "14991    1\n",
      "21671    1\n",
      "33505    1\n",
      "1851     1\n",
      "8621    -1\n",
      "4980     1\n",
      "42075    1\n",
      "23205    1\n",
      "33565    1\n",
      "11464    1\n",
      "11289    1\n",
      "3409     1\n",
      "34303   -1\n",
      "32239   -1\n",
      "29774   -1\n",
      "3117     1\n",
      "18311    1\n",
      "32630   -1\n",
      "20242    1\n",
      "20675    1\n",
      "4258     1\n",
      "4827     1\n",
      "15595    1\n",
      "12981    1\n",
      "30423    1\n",
      "8604     1\n",
      "42831    1\n",
      "Name: label, Length: 11626, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Посмотрим метки на тестовой выборке\n",
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Сравним с предсказаниями, сделанными нашей моделью на тестовой выборке:\n",
    "predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда мы используем логистическую регрессию, мы работаем с вероятностной моделью. \n",
    "Помимо меток классов, эта модель может выдать нам вероятности, с которыми каждый объект принадлежит классу 0, 1 или -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.91623084e-04, 1.11482831e-02, 9.88660094e-01],\n",
       "       [4.98672807e-07, 4.71632279e-04, 9.99527869e-01],\n",
       "       [1.23753931e-04, 1.13042469e-04, 9.99763204e-01],\n",
       "       ...,\n",
       "       [4.06295504e-04, 8.00816177e-05, 9.99513623e-01],\n",
       "       [3.10519133e-03, 4.01203704e-04, 9.96493605e-01],\n",
       "       [8.76832176e-03, 1.65094714e-02, 9.74722207e-01]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Построим эти вероятности. Для этого нужно воспользоваться методом predict_proba (или predict probability). \n",
    "#В качестве аргумента передаем тестовую выборку и получаем наши вероятности принадлежности к классам.\n",
    "lr.predict_proba(test_data) \n",
    "\n",
    "#Мы видим, что для каждого объекта нам доступны следующие значения: вероятность принадлежности объекта к классу 0, -1, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.50      0.57      1114\n",
      "           0       0.39      0.25      0.30      1413\n",
      "           1       0.88      0.95      0.91      9099\n",
      "\n",
      "    accuracy                           0.82     11626\n",
      "   macro avg       0.64      0.57      0.60     11626\n",
      "weighted avg       0.80      0.82      0.81     11626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_vec = vec.transform(['Не советую смотреть данный фильм: плохая игра актеров, примитивный сценарий!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(my_vec) #Тут модель неверно предсказала. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['отличный',\n",
       " 'приятно',\n",
       " 'отлично',\n",
       " 'самих',\n",
       " 'лучших',\n",
       " 'пересматривать',\n",
       " 'дыхании',\n",
       " 'становятся',\n",
       " 'слегка',\n",
       " 'спорю']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим на 10 наиболее важных признаков для модели:\n",
    "coeffs = lr.coef_[0]\n",
    "feats10 = [vec.get_feature_names()[list(coeffs).index(i)] for i in sorted(coeffs)[:10]]\n",
    "feats10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем выставить параметр solver = 'newton-cg' в  логрегрессии: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solver = 'newton-cg'применяют для мультиклассовой классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_newton = LogisticRegression(random_state=1, solver = 'newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Обучение нашего классификатора\n",
    "lr_newton.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Строим предсказания на тестовой выборке:\n",
    "predicted_labels = lr.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.50      0.57      1114\n",
      "           0       0.39      0.25      0.30      1413\n",
      "           1       0.88      0.95      0.91      9099\n",
      "\n",
      "    accuracy                           0.82     11626\n",
      "   macro avg       0.64      0.57      0.60     11626\n",
      "weighted avg       0.80      0.82      0.81     11626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество по accuracy не изменилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизируем текст, используя биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Инициализируем CountVectorizer, используя биграммы:\n",
    "vec = CountVectorizer(ngram_range=(2, 2))\n",
    "bow = vec.fit_transform(df.text)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(bow, df.label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.35      0.46      1070\n",
      "           0       0.48      0.11      0.18      1425\n",
      "           1       0.84      0.99      0.91      9131\n",
      "\n",
      "    accuracy                           0.82     11626\n",
      "   macro avg       0.66      0.48      0.51     11626\n",
      "weighted avg       0.78      0.82      0.78     11626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Обучаем модель с биграммами\n",
    "lr = LogisticRegression(random_state=1)\n",
    "lr.fit(train_data, train_labels)\n",
    "predicted_labels = lr.predict(test_data)\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество по accuracy не изменилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизуем текст, используя токенизатор из NLTK, а также список стоп-слов оттуда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_stopwords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.51      0.58      1085\n",
      "           0       0.36      0.22      0.27      1413\n",
      "           1       0.88      0.95      0.91      9128\n",
      "\n",
      "    accuracy                           0.82     11626\n",
      "   macro avg       0.63      0.56      0.59     11626\n",
      "weighted avg       0.79      0.82      0.80     11626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(tokenizer=word_tokenize, stop_words=rus_stopwords) #используем токенизатор из нлтк и стоп слова\n",
    "bow = vec.fit_transform(df.text)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(bow, df.label) \n",
    "lr = LogisticRegression(random_state=1)\n",
    "lr.fit(train_data, train_labels)\n",
    "predicted_labels = lr.predict(test_data)\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество по accuracy не изменилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование TF-IDF векторизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.74      0.36      0.48      1081\n",
      "           0       0.49      0.07      0.12      1314\n",
      "           1       0.84      0.99      0.91      9231\n",
      "\n",
      "    accuracy                           0.83     11626\n",
      "   macro avg       0.69      0.47      0.50     11626\n",
      "weighted avg       0.79      0.83      0.78     11626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(df.text)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(bow, df.label) \n",
    "lr = LogisticRegression(random_state=1)\n",
    "lr.fit(train_data, train_labels)\n",
    "predicted_labels = lr.predict(test_data)\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Качество с TfidfVectorizer чуть лучше!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подбор параметров для логистической регрессии с помощью GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "bow = vec.fit_transform(df.text)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(bow, df.label) \n",
    "lr = LogisticRegression(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'class_weight', 'dual', 'fit_intercept', 'intercept_scaling', 'l1_ratio', 'max_iter', 'multi_class', 'n_jobs', 'penalty', 'random_state', 'solver', 'tol', 'verbose', 'warm_start'])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим, какие параметры мы можем подобрать: \n",
    "lr.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "penalty - регуляризация\n",
    "С - обратный коэффициент регуляризации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_values = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\n",
    "grid_lr_acc = GridSearchCV(lr, param_grid = grid_values, scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=1, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.001, 0.009, 0.01, 0.09, 1, 5, 10, 25],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lr_acc.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.09, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Посмотрим на лучший классификатор (возвращает модель с лучшими параметрами):\n",
    "grid_lr_acc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8299928315412186\n",
      "{'C': 0.09, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "#Отдельно можно посмотреть на оценку на лучшем наборе параметров:\n",
    "print(grid_lr_acc.best_score_)\n",
    "\n",
    "#Вывести лучшие наборы параметров: \n",
    "print(grid_lr_acc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтобы посмотреть оценки на первых 10 наборах:  #Не работает!\n",
    "grid_lr_acc.grid_scores_[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию снова, выставив параметры, рекомендованные GridSearch. Регуляризация L2 стоит по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.69      0.53      0.60      1081\n",
      "           0       0.42      0.21      0.28      1382\n",
      "           1       0.88      0.97      0.92      9163\n",
      "\n",
      "    accuracy                           0.84     11626\n",
      "   macro avg       0.66      0.57      0.60     11626\n",
      "weighted avg       0.81      0.84      0.81     11626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=1,C = 0.09)\n",
    "lr.fit(train_data, train_labels)\n",
    "predicted_labels = lr.predict(test_data)\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Нам удалось поднять качество у логрегрессии на 0.2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Протестируем какой-нибудь отрывок из отзыва из Интернета:\n",
    "my_vec = vec.transform(['Впечатления в итоге сдержанные и смешанные. Фильм меня не захватил. По большей части, два часа в кадре показывают действия и озвучивают мысли одного человека, который не вызвал у меня симпатии сразу, показался старше, чем ему прописано быть в сценарии. Не захотелось ему сопереживать. Сходу возникло предположение, что от него следует ожидать каких-то неадекватных поступков.'])\n",
    "lr.predict(my_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование разных классификаторов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация с помощью наивного Байесовского классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer()\n",
    "bow = vec.fit_transform(df.text)\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(bow, df.label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.22      0.33      1110\n",
      "           0       0.35      0.07      0.12      1464\n",
      "           1       0.81      0.98      0.89      9052\n",
      "\n",
      "    accuracy                           0.79     11626\n",
      "   macro avg       0.62      0.42      0.45     11626\n",
      "weighted avg       0.74      0.79      0.74     11626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Инициализируем Байесовский классификатор: \n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_data, train_labels)\n",
    "predicted_labels = nb.predict(test_data)\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель, обученная с помощью наивного байесовского классификатора показало качество _хуже_, чем с логрегрессией. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация с помощью деревьев решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея метода: каждый признак - это критерий, это критерий, чтобы выбрать к какому классу относится объект. Мы можем построить дерево, где каждый узел - это разветвление по признакам. \n",
    "Корень - самый значимый признак, а дальше другие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.26      0.22      0.24      1110\n",
      "           0       0.18      0.14      0.16      1464\n",
      "           1       0.82      0.86      0.84      9052\n",
      "\n",
      "    accuracy                           0.71     11626\n",
      "   macro avg       0.42      0.41      0.41     11626\n",
      "weighted avg       0.68      0.71      0.69     11626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(train_data, train_labels)\n",
    "predicted_labels = dtc.predict(test_data)\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель, обученная с помощью алгоритма деревьев решений показало качество _хуже_, чем с логрегрессией."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация с помощью метода k ближайших соседей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея метода: это предположение о том, что схожие (близкие в пространстве признаков) объекты гораздо чаще лежат в одном классе, чем в разных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mleaf_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minkowski'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmetric_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Classifier implementing the k-nearest neighbors vote.\n",
       "\n",
       "Read more in the :ref:`User Guide <classification>`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "n_neighbors : int, optional (default = 5)\n",
       "    Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
       "\n",
       "weights : str or callable, optional (default = 'uniform')\n",
       "    weight function used in prediction.  Possible values:\n",
       "\n",
       "    - 'uniform' : uniform weights.  All points in each neighborhood\n",
       "      are weighted equally.\n",
       "    - 'distance' : weight points by the inverse of their distance.\n",
       "      in this case, closer neighbors of a query point will have a\n",
       "      greater influence than neighbors which are further away.\n",
       "    - [callable] : a user-defined function which accepts an\n",
       "      array of distances, and returns an array of the same shape\n",
       "      containing the weights.\n",
       "\n",
       "algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, optional\n",
       "    Algorithm used to compute the nearest neighbors:\n",
       "\n",
       "    - 'ball_tree' will use :class:`BallTree`\n",
       "    - 'kd_tree' will use :class:`KDTree`\n",
       "    - 'brute' will use a brute-force search.\n",
       "    - 'auto' will attempt to decide the most appropriate algorithm\n",
       "      based on the values passed to :meth:`fit` method.\n",
       "\n",
       "    Note: fitting on sparse input will override the setting of\n",
       "    this parameter, using brute force.\n",
       "\n",
       "leaf_size : int, optional (default = 30)\n",
       "    Leaf size passed to BallTree or KDTree.  This can affect the\n",
       "    speed of the construction and query, as well as the memory\n",
       "    required to store the tree.  The optimal value depends on the\n",
       "    nature of the problem.\n",
       "\n",
       "p : integer, optional (default = 2)\n",
       "    Power parameter for the Minkowski metric. When p = 1, this is\n",
       "    equivalent to using manhattan_distance (l1), and euclidean_distance\n",
       "    (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
       "\n",
       "metric : string or callable, default 'minkowski'\n",
       "    the distance metric to use for the tree.  The default metric is\n",
       "    minkowski, and with p=2 is equivalent to the standard Euclidean\n",
       "    metric. See the documentation of the DistanceMetric class for a\n",
       "    list of available metrics.\n",
       "\n",
       "metric_params : dict, optional (default = None)\n",
       "    Additional keyword arguments for the metric function.\n",
       "\n",
       "n_jobs : int or None, optional (default=None)\n",
       "    The number of parallel jobs to run for neighbors search.\n",
       "    ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
       "    ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
       "    for more details.\n",
       "    Doesn't affect :meth:`fit` method.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> X = [[0], [1], [2], [3]]\n",
       ">>> y = [0, 0, 1, 1]\n",
       ">>> from sklearn.neighbors import KNeighborsClassifier\n",
       ">>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
       ">>> neigh.fit(X, y) # doctest: +ELLIPSIS\n",
       "KNeighborsClassifier(...)\n",
       ">>> print(neigh.predict([[1.1]]))\n",
       "[0]\n",
       ">>> print(neigh.predict_proba([[0.9]]))\n",
       "[[0.66666667 0.33333333]]\n",
       "\n",
       "See also\n",
       "--------\n",
       "RadiusNeighborsClassifier\n",
       "KNeighborsRegressor\n",
       "RadiusNeighborsRegressor\n",
       "NearestNeighbors\n",
       "\n",
       "Notes\n",
       "-----\n",
       "See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
       "for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
       "\n",
       ".. warning::\n",
       "\n",
       "   Regarding the Nearest Neighbors algorithms, if it is found that two\n",
       "   neighbors, neighbor `k+1` and `k`, have identical distances\n",
       "   but different labels, the results will depend on the ordering of the\n",
       "   training data.\n",
       "\n",
       "https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
       "\u001b[0;31mFile:\u001b[0m           /anaconda3/lib/python3.7/site-packages/sklearn/neighbors/classification.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.22      0.13      0.16      1110\n",
      "           0       0.16      0.12      0.14      1464\n",
      "           1       0.80      0.88      0.84      9052\n",
      "\n",
      "    accuracy                           0.71     11626\n",
      "   macro avg       0.40      0.37      0.38     11626\n",
      "weighted avg       0.66      0.71      0.68     11626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn.fit(train_data, train_labels)\n",
    "predicted_labels = knn.predict(test_data)\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель, обученная с помощью метода k ближайших соседей, показало качество _хуже_, чем с логрегрессией. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем другой линейный классификатор - SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.43      0.52      1110\n",
      "           0       0.32      0.32      0.32      1464\n",
      "           1       0.88      0.92      0.90      9052\n",
      "\n",
      "    accuracy                           0.80     11626\n",
      "   macro avg       0.62      0.56      0.58     11626\n",
      "weighted avg       0.79      0.80      0.79     11626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgdcl = SGDClassifier(random_state=1)\n",
    "sgdcl.fit(train_data, train_labels)\n",
    "predicted_labels = sgdcl.predict(test_data)\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество хуже, чем у логрегрессии. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем еще один линейный классификатор LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.61      0.53      0.57      1110\n",
      "           0       0.35      0.26      0.30      1464\n",
      "           1       0.88      0.93      0.91      9052\n",
      "\n",
      "    accuracy                           0.81     11626\n",
      "   macro avg       0.61      0.58      0.59     11626\n",
      "weighted avg       0.79      0.81      0.80     11626\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "l_SVC = LinearSVC(random_state=1)\n",
    "l_SVC.fit(train_data, train_labels)\n",
    "predicted_labels = l_SVC.predict(test_data)\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество хуже, чем у логрегрессии. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
